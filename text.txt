import argparse
import json
import logging
from jinja2 import Template
import ast
import time
import requests
import glob

# Initialize logger
logger = logging.getLogger(__name__)

class ConfigurationFetcher:
    def __init__(self, env):
        self.env = env

    def fetch_datasets_config(self, package_id):
        provider, package = package_id.split("/")
        url = f"http://datazone-metazone-service-{self.env}-ms.com/v2/datasets/hierarchy?fully_qualified_name={provider}/{package}"
        
        try:
            resp = self._make_request(url)
        except requests.exceptions.RequestException as ex:
            logger.error(f"Failed to fetch config for {package_id}: {ex}")
            raise Exception(f"Failed after retries for {url}")
        
        return self._parse_response(resp)

    def _make_request(self, url, retry_delay=480):
        try:
            resp = requests.get(url, timeout=300)
            resp.raise_for_status()
            return resp
        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as ex:
            logger.warning(f"Request failed: {ex}. Retrying after {retry_delay} seconds...")
            time.sleep(retry_delay)
            return requests.get(url)

    def _parse_response(self, resp):
        resp.encoding = resp.encoding or 'utf-8'
        data = resp.json()
        
        package_config = data['dataSetHierarchy']['dataSetProviders'][0]['packages'][0]
        datasets_configs = package_config.pop('datasets', [])
        provider_config = data['dataSetHierarchy']['dataSetProviders'][0]
        
        return provider_config, package_config, datasets_configs

class ConfigurationProcessor:
    @staticmethod
    def convert_to_config_store_format(provider_config, package_config, dataset_config):
        configurations = {
            key: ConfigurationProcessor._map_catalog_configuration(config, key) 
            for key, config in zip(['provider', 'package', 'dataset'], (provider_config, package_config, dataset_config))
        }

        configurations['package']['package_id'] = f"{configurations['provider']['provider_id']}/{configurations['package']['package_id']}"
        configurations['dataset']['dataset_id'] = f"{configurations['package']['package_id']}/{configurations['dataset']['dataset_id']}"

        code_access_meta = dataset_config.get('codeAccessMeta', {})
        if isinstance(code_access_meta, dict) and code_access_meta:
            env_config = dataset_config.get('codeAccessProtocol', {}).get(args.env)
            if env_config:
                template = Template(json.dumps(code_access_meta))
                configurations['dataset'].update(json.loads(template.render(env_config)))
        else:
            configurations['dataset'] = None

        return configurations['provider'], configurations['package'], configurations['dataset']

    @staticmethod
    def _map_catalog_configuration(config, config_type):
        # Placeholder for actual configuration mapping logic
        return config

class ConfigurationWriter:
    def __init__(self, config_store_interface):
        self.config_store_interface = config_store_interface

    def write(self, provider_config, package_config, dataset_config):
        try:
            self.config_store_interface.set_provider_config(provider_config['provider_id'], provider_config)
        except Exception as ex:
            logger.exception(f"Failed to write provider config: {ex}")
        
        try:
            self.config_store_interface.set_package_config(package_config['package_id'], package_config)
        except Exception as ex:
            logger.exception(f"Failed to write package config: {ex}")

        if dataset_config:
            try:
                self.config_store_interface.set_dataset_config(dataset_config['dataset_id'], dataset_config)
            except Exception as ex:
                logger.exception(f"Failed to write dataset config: {ex}")

class TeamDznodePackagesFetcher:
    @staticmethod
    def get_team_dznode_packages(env, team_dznode):
        team_dznode_packages = []
        for provider, package in [
            x.split("/")[-2:] for x in glob.glob(
                f"/ms/dist/datazone/PROJ/dzdata.accessible/{env}/accessible_dataset/{env}/dznode/data/providers/*/*"
            ) if not x.endswith("-py")
        ]:
            team_dznode_packages.append(f"{provider}/{package}")
        return team_dznode_packages

def main():
    parser = argparse.ArgumentParser(description='Dataset to config store app', add_help=True)
    parser.add_argument("-env", "--environment", dest="env", required=True, help="Environment to release", type=str)
    parser.add_argument("-name", "--team_dznode", dest="name", required=True, default="community", help="Team dznode name", type=str)
    args = parser.parse_args()

    fetcher = ConfigurationFetcher(args.env)
    writer = ConfigurationWriter(ConfigStoreInterface(GPFSConfigStore(root_path="var/temp/accessible/")))
    
    team_dznode_packages = TeamDznodePackagesFetcher.get_team_dznode_packages(args.env, args.name)
    
    for package_id in team_dznode_packages:
        provider_config, package_config, datasets_configs = fetcher.fetch_datasets_config(package_id)
        
        for dataset_config in datasets_configs:
            provider, package, dataset = ConfigurationProcessor.convert_to_config_store_format(provider_config, package_config, dataset_config)
            writer.write(provider, package, dataset)

if __name__ == "__main__":
    main()
